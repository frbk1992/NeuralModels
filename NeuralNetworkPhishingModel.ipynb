{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#this is the same util2 used for the first assigment\n",
    "from util2 import Arff2Skl\n",
    "import arff\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['having_IP_Address' 'URL_Length' 'Shortining_Service' 'having_At_Symbol'\n",
      " 'double_slash_redirecting' 'Prefix_Suffix' 'having_Sub_Domain'\n",
      " 'SSLfinal_State' 'Domain_registeration_length' 'Favicon' 'port'\n",
      " 'HTTPS_token' 'Request_URL' 'URL_of_Anchor' 'Links_in_tags' 'SFH'\n",
      " 'Submitting_to_email' 'Abnormal_URL' 'Redirect' 'on_mouseover'\n",
      " 'RightClick' 'popUpWidnow' 'Iframe' 'age_of_domain' 'DNSRecord'\n",
      " 'web_traffic' 'Page_Rank' 'Google_Index' 'Links_pointing_to_page'\n",
      " 'Statistical_report' 'Result']\n"
     ]
    }
   ],
   "source": [
    "#parse the phishing.arff dataset\n",
    "cvt = Arff2Skl(\"phishing.arff\")\n",
    "label = np.array(cvt.meta.names())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = cvt.transform()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modifythe type from np.float64 (default type) to np.float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = arff.load(open('phishing.arff', 'r'))\n",
    "data = np.array(dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11055, 31)\n",
      "(11055, 2)\n",
      "(11055, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "#y = data[:,-1]\n",
    "X = data[:,:-1]\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "#get the X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, y = cvt.transform()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7406, 30)\n",
      "(7406, 2)\n",
      "(3649, 30)\n",
      "(3649, 2)\n"
     ]
    }
   ],
   "source": [
    "#modifythe type from np.float64 (default type) to np.float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "#print the shape of the matrix's\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the classifier\n",
    "learning_rate = 0.001\n",
    "batch_size = 128 #the classifier will take blocks of 128 to run the classifier\n",
    "display_step = 5\n",
    "num_steps = int(X_train.shape[0]/batch_size) # 58 = ceil(7406/128) = ceil(57.85)\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 30 # number of features\n",
    "num_classes = 2 # total amount of classes\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None], name=\"input\")\n",
    "Y = tf.placeholder(tf.int32, [None, num_classes], name=\"outputY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "this code create the model with random values for each weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias (this should work without any change)\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model (this should work without any change)\n",
    "def neural_net(x):\n",
    "    x_matrix = tf.reshape(x, [-1, num_input])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x_matrix, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model (this should work without any change)\n",
    "logits = neural_net(X)\n",
    "sofmax_out = tf.nn.softmax(logits)\n",
    "# Define loss and optimizer\n",
    "out = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name=\"output2\")\n",
    "loss_op = tf.reduce_mean(out)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 30)\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:batch_size].shape)\n",
    "#from Math import floor\n",
    "print(int(7406/128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "this code train the model and find the most optimal value for each weight and every bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Testing Accuracy: 0.890929\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(1, num_steps+1):\n",
    "        batch_x = X_train[(i-1)*batch_size: (i-1)*batch_size + batch_size] #take a block of 128 instances\n",
    "        batch_y = y_train[(i-1)*batch_size: (i-1)*batch_size + batch_size] #take a block of 128 instances\n",
    "        batch_x = batch_x.ravel().astype(np.float32)\n",
    "        #print(type(batch_x))\n",
    "        #print(type(batch_y))\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "       \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for test instances\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: X_test.ravel(), Y: y_test}))\n",
    "    \n",
    "    y_out = sess.run(sofmax_out, feed_dict={X: X_test.ravel()})\n",
    "    \n",
    "    #all_saver = tf.train.Saver()\n",
    "    #all_saver.save(sess, '/model/model.ckpt')\n",
    "    \n",
    "    #this variables are used for the binary model, catch the current state for every weight and every bias\n",
    "    W1 = weights['h1'].eval(sess)\n",
    "    B1 = biases['b1'].eval(sess)\n",
    "    W2 = weights['h2'].eval(sess)\n",
    "    B2 = biases['b2'].eval(sess)\n",
    "    W_OUT = weights['out'].eval(sess)\n",
    "    B_OUT = biases['out'].eval(sess)\n",
    "    \n",
    "    #print(sess.run(weights.get('h1')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "0.89092902165\n",
      "0.779027089455\n"
     ]
    }
   ],
   "source": [
    "print(y_out)\n",
    "print(np.mean((y_test - y_out.round()) == 0))\n",
    "print(matthews_corrcoef(y_test[:,0], y_out.round()[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Model\n",
    "\n",
    "This Code export the model as a binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check accuracy 0.904905\n"
     ]
    }
   ],
   "source": [
    "# Create new graph for exporting\n",
    "\n",
    "DIR = '/model/' # path where the model will be create it\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    # this steps are the same as the function neural_net() but instead of random values will \n",
    "    # take the value in every weight and every bias at the end of the classifier\n",
    "    \n",
    "    #create the input parameter which is a vector\n",
    "    x_2 = tf.placeholder(tf.float32, shape=[None], name=\"input\")\n",
    "    \n",
    "    #reshape the vector into a matrix, this has to be done because the the op matmul\n",
    "    #requires two matrix's\n",
    "    x_22 = tf.reshape(x_2, [-1, num_input])\n",
    "    \n",
    "    #create each weight and each biase with the final value\n",
    "    W1_C = tf.constant(W1, name=\"W1\")\n",
    "    B1_C = tf.constant(B1, name=\"B1\")\n",
    "    W2_C = tf.constant(W2, name=\"W2\")\n",
    "    B2_C = tf.constant(B2, name=\"B2\")\n",
    "    W_OUT_C = tf.constant(W_OUT, name=\"W_OUT\")\n",
    "    B_OUT_C = tf.constant(B_OUT, name=\"B_OUT\")\n",
    "    \n",
    "    \n",
    "    # the two layers as used in neural_net()\n",
    "    layer_1 = tf.add(tf.matmul(x_22, W1_C, name=\"matmul_x_22_w1_c\"), B1_C, name=\"add_matmul1_b1_c\")\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, W2_C, name=\"matmul_l_1_w1_c\"), B2_C, name=\"add_matmul2_b2_c\")\n",
    "    #the output value of the classifier with the name output\n",
    "    OUTPUT = tf.nn.softmax(tf.matmul(layer_2, W_OUT, name=\"matmul_l_2_wout_c\") + B_OUT, name=\"output\")\n",
    "    \n",
    "\n",
    "    # skipped dropout for exported graph as there is no need for already calculated weights\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    graph_def = g.as_graph_def()\n",
    "    \n",
    "    #create the model model_graph.pb\n",
    "    tf.train.write_graph(graph_def, DIR, 'phishing_model_opt4.pb', as_text=False)\n",
    "\n",
    "    \n",
    "    # Test trained model\n",
    "    y_train = tf.placeholder(tf.float32, [None, num_classes])\n",
    "    correct_prediction = tf.equal(tf.argmax(OUTPUT, 1), tf.argmax(y_train, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    print(\"check accuracy %g\" % accuracy.eval({x_2: X_test.ravel(), y_train: y_test}, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  0.  1. -1. -1.\n",
      "  1.  0.  1.  1.]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of the custom library made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuron import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from time import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the samples\n",
    "dataset = arff.load(open('phishing2.arff', 'r'))\n",
    "data = np.array(dataset['data'])\n",
    "X = data[:,:-1]\n",
    "\n",
    "#get the labels\n",
    "cvt = Arff2Skl(\"phishing2.arff\")\n",
    "_, y = cvt.transform()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Done in  541.8984749317169\n"
     ]
    }
   ],
   "source": [
    "accs = np.zeros(5*10).reshape(5,10)\n",
    "mccs = np.zeros(5*10).reshape(5,10)\n",
    "t1 = time()\n",
    "for j ,i in enumerate(range(219, 224)):\n",
    "    ##get a number random set of train and test\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random.randint(1,100))\n",
    "    k = 0\n",
    "    for train, test in kf.split(X):\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        clf = NeuronNetworkTwoHiddenLayer(n_hidden_1 = 256+i, n_hidden_2 = 256+i)\n",
    "        clf.train(X_train, y_train)\n",
    "        y_out = clf.predict(X_test)\n",
    "        accs[j][k] = matthews_corrcoef(y_test[:,0], y_out.round()[:,0])\n",
    "        mccs[j][k] = np.mean((y_test - y_out.round()) == 0)\n",
    "        k +=1\n",
    "        clf.clear()\n",
    "        del y_out\n",
    "        del clf\n",
    "    del kf\n",
    "    print(j)\n",
    "print('Done in ', time() - t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
